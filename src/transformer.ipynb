{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from pytorch_pretrained_vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/B_16_imagenet1k.pth\" to /Users/justinwang/.cache/torch/hub/checkpoints/B_16_imagenet1k.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'B_16_imagenet1k'\n",
    "model = ViT(model_name, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessing/preprocessed_data_split_nona_03_06.pkl', 'rb') as f:\n",
    "    train, val, test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repeat</th>\n",
       "      <th>gender</th>\n",
       "      <th>mel</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>chromagram</th>\n",
       "      <th>spec_contrast</th>\n",
       "      <th>tonnetz</th>\n",
       "      <th>filename</th>\n",
       "      <th>mel_pad</th>\n",
       "      <th>mfcc_pad</th>\n",
       "      <th>chromagram_pad</th>\n",
       "      <th>spec_contrast_pad</th>\n",
       "      <th>tonnetz_pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-976.11755, -976.11755, -976.11755, -976.117...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[18.698652440717126, 18.698652440717126, 18.6...</td>\n",
       "      <td>[[-0.24351785481696392, -0.22269760507170488, ...</td>\n",
       "      <td>03-01-02-01-02-02-20.wav</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-976.1175537109375, -976.1175537109375, -976...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[18.698652440717126, 18.698652440717126, 18.6...</td>\n",
       "      <td>[[-0.24351785481696392, -0.22269760507170488, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-919.54193, -919.54193, -919.54193, -919.541...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[14.30063620727286, 14.30063620727286, 14.300...</td>\n",
       "      <td>[[0.011945099331460431, 0.02484843939140515, 0...</td>\n",
       "      <td>03-01-06-01-01-01-14.wav</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-919.5419311523438, -919.5419311523438, -919...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[14.30063620727286, 14.30063620727286, 14.300...</td>\n",
       "      <td>[[0.011945099331460431, 0.02484843939140515, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[5.976571e-14, 3.2825318e-09, 4.7936957e-09, ...</td>\n",
       "      <td>[[-735.2311, -735.2311, -735.2311, -735.2311, ...</td>\n",
       "      <td>[[0.91999584, 0.9419208, 0.9717938, 1.0, 1.0, ...</td>\n",
       "      <td>[[27.160881999404914, 10.240644242524503, 17.3...</td>\n",
       "      <td>[[-0.039178584692475336, -0.07856553551372042,...</td>\n",
       "      <td>03-01-07-01-02-01-04.wav</td>\n",
       "      <td>[[5.976570963388966e-14, 3.282531801929167e-09...</td>\n",
       "      <td>[[-735.2310791015625, -735.2310791015625, -735...</td>\n",
       "      <td>[[0.9199958443641663, 0.941920816898346, 0.971...</td>\n",
       "      <td>[[27.160881999404914, 10.240644242524503, 17.3...</td>\n",
       "      <td>[[-0.039178584692475336, -0.07856553551372042,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[5.161722e-06, 1.9711595e-06, 1.4549606e-07, ...</td>\n",
       "      <td>[[-760.2454, -761.35565, -763.5334, -763.5334,...</td>\n",
       "      <td>[[0.7726974, 0.86186564, 0.8380048, 0.6996503,...</td>\n",
       "      <td>[[25.352601414654497, 17.07070284635677, 10.08...</td>\n",
       "      <td>[[-0.09442284617849674, -0.08483387511976943, ...</td>\n",
       "      <td>03-01-05-01-02-01-06.wav</td>\n",
       "      <td>[[5.16172212883248e-06, 1.971159463209915e-06,...</td>\n",
       "      <td>[[-760.2454223632812, -761.3556518554688, -763...</td>\n",
       "      <td>[[0.772697389125824, 0.8618656396865845, 0.838...</td>\n",
       "      <td>[[25.352601414654497, 17.07070284635677, 10.08...</td>\n",
       "      <td>[[-0.09442284617849674, -0.08483387511976943, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[2.1212953e-11, 1.1371189e-10, 2.6217887e-13,...</td>\n",
       "      <td>[[-766.1009, -766.1009, -766.1009, -766.1009, ...</td>\n",
       "      <td>[[0.8027966, 0.9662601, 0.93856305, 0.934313, ...</td>\n",
       "      <td>[[20.23687827597825, 13.043456325271165, 21.71...</td>\n",
       "      <td>[[0.15901379770687685, 0.10643275780873687, 0....</td>\n",
       "      <td>03-01-04-02-02-01-14.wav</td>\n",
       "      <td>[[2.1212953268956447e-11, 1.1371188712860913e-...</td>\n",
       "      <td>[[-766.1008911132812, -766.1008911132812, -766...</td>\n",
       "      <td>[[0.8027966022491455, 0.9662600755691528, 0.93...</td>\n",
       "      <td>[[20.23687827597825, 13.043456325271165, 21.71...</td>\n",
       "      <td>[[0.15901379770687685, 0.10643275780873687, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion  intensity  statement  repeat  gender  \\\n",
       "195         2          1          2       2       0   \n",
       "1048        6          1          1       1       0   \n",
       "532         7          1          2       1       0   \n",
       "1273        5          1          2       1       0   \n",
       "1064        4          2          2       1       0   \n",
       "\n",
       "                                                    mel  \\\n",
       "195   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1048  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "532   [[5.976571e-14, 3.2825318e-09, 4.7936957e-09, ...   \n",
       "1273  [[5.161722e-06, 1.9711595e-06, 1.4549606e-07, ...   \n",
       "1064  [[2.1212953e-11, 1.1371189e-10, 2.6217887e-13,...   \n",
       "\n",
       "                                                   mfcc  \\\n",
       "195   [[-976.11755, -976.11755, -976.11755, -976.117...   \n",
       "1048  [[-919.54193, -919.54193, -919.54193, -919.541...   \n",
       "532   [[-735.2311, -735.2311, -735.2311, -735.2311, ...   \n",
       "1273  [[-760.2454, -761.35565, -763.5334, -763.5334,...   \n",
       "1064  [[-766.1009, -766.1009, -766.1009, -766.1009, ...   \n",
       "\n",
       "                                             chromagram  \\\n",
       "195   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1048  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "532   [[0.91999584, 0.9419208, 0.9717938, 1.0, 1.0, ...   \n",
       "1273  [[0.7726974, 0.86186564, 0.8380048, 0.6996503,...   \n",
       "1064  [[0.8027966, 0.9662601, 0.93856305, 0.934313, ...   \n",
       "\n",
       "                                          spec_contrast  \\\n",
       "195   [[18.698652440717126, 18.698652440717126, 18.6...   \n",
       "1048  [[14.30063620727286, 14.30063620727286, 14.300...   \n",
       "532   [[27.160881999404914, 10.240644242524503, 17.3...   \n",
       "1273  [[25.352601414654497, 17.07070284635677, 10.08...   \n",
       "1064  [[20.23687827597825, 13.043456325271165, 21.71...   \n",
       "\n",
       "                                                tonnetz  \\\n",
       "195   [[-0.24351785481696392, -0.22269760507170488, ...   \n",
       "1048  [[0.011945099331460431, 0.02484843939140515, 0...   \n",
       "532   [[-0.039178584692475336, -0.07856553551372042,...   \n",
       "1273  [[-0.09442284617849674, -0.08483387511976943, ...   \n",
       "1064  [[0.15901379770687685, 0.10643275780873687, 0....   \n",
       "\n",
       "                      filename  \\\n",
       "195   03-01-02-01-02-02-20.wav   \n",
       "1048  03-01-06-01-01-01-14.wav   \n",
       "532   03-01-07-01-02-01-04.wav   \n",
       "1273  03-01-05-01-02-01-06.wav   \n",
       "1064  03-01-04-02-02-01-14.wav   \n",
       "\n",
       "                                                mel_pad  \\\n",
       "195   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1048  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "532   [[5.976570963388966e-14, 3.282531801929167e-09...   \n",
       "1273  [[5.16172212883248e-06, 1.971159463209915e-06,...   \n",
       "1064  [[2.1212953268956447e-11, 1.1371188712860913e-...   \n",
       "\n",
       "                                               mfcc_pad  \\\n",
       "195   [[-976.1175537109375, -976.1175537109375, -976...   \n",
       "1048  [[-919.5419311523438, -919.5419311523438, -919...   \n",
       "532   [[-735.2310791015625, -735.2310791015625, -735...   \n",
       "1273  [[-760.2454223632812, -761.3556518554688, -763...   \n",
       "1064  [[-766.1008911132812, -766.1008911132812, -766...   \n",
       "\n",
       "                                         chromagram_pad  \\\n",
       "195   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1048  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "532   [[0.9199958443641663, 0.941920816898346, 0.971...   \n",
       "1273  [[0.772697389125824, 0.8618656396865845, 0.838...   \n",
       "1064  [[0.8027966022491455, 0.9662600755691528, 0.93...   \n",
       "\n",
       "                                      spec_contrast_pad  \\\n",
       "195   [[18.698652440717126, 18.698652440717126, 18.6...   \n",
       "1048  [[14.30063620727286, 14.30063620727286, 14.300...   \n",
       "532   [[27.160881999404914, 10.240644242524503, 17.3...   \n",
       "1273  [[25.352601414654497, 17.07070284635677, 10.08...   \n",
       "1064  [[20.23687827597825, 13.043456325271165, 21.71...   \n",
       "\n",
       "                                            tonnetz_pad  \n",
       "195   [[-0.24351785481696392, -0.22269760507170488, ...  \n",
       "1048  [[0.011945099331460431, 0.02484843939140515, 0...  \n",
       "532   [[-0.039178584692475336, -0.07856553551372042,...  \n",
       "1273  [[-0.09442284617849674, -0.08483387511976943, ...  \n",
       "1064  [[0.15901379770687685, 0.10643275780873687, 0....  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 250)\n",
      "(6, 250)\n",
      "(20, 250)\n",
      "(12, 250)\n",
      "(7, 250)\n",
      "(384, 384)\n",
      "1152\n"
     ]
    }
   ],
   "source": [
    "# 256 + 6 + 20 + 12 + 7 = 256 + 45 = 301\n",
    "print(train['mel_pad'][0].shape)\n",
    "print(train['tonnetz_pad'][0].shape)\n",
    "print(train['mfcc_pad'][0].shape)\n",
    "print(train['chromagram_pad'][0].shape)\n",
    "print(train['spec_contrast_pad'][0].shape)\n",
    "print(model.image_size)\n",
    "print(len(train['mel_pad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# implementing a mel-only version\n",
    "class TransformerDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.labels = df['emotion'].reset_index(drop=True)\n",
    "        self.num_labels = self.labels.nunique()\n",
    "        self.mels = df['mel_pad'].reset_index(drop=True)\n",
    "        self.max_len = self.mels[0].shape[1]\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                             transforms.CenterCrop(model.image_size),])\n",
    "                                             #transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                                  #[0.5, 0.5, 0.5]),])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        mel = self.mels.iloc[idx]\n",
    "        label = self.labels.iloc[idx]        \n",
    "        mel = self.transform(mel)\n",
    "        # stack the same mel spectrogram three times to emulate RGB image\n",
    "        mel = torch.stack([mel]*3, dim=1).squeeze(dim=0).type(torch.float)\n",
    "        label = torch.tensor(label-1).type(torch.long)\n",
    "        \n",
    "        return mel, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152\n",
      "torch.Size([3, 384, 384])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TransformerDataset(train)\n",
    "print(len(train_dataset))\n",
    "print(train_dataset[0][0].shape)\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "img = train_dataset[0]['mel']\n",
    "with torch.no_grad():\n",
    "    outputs = model(img.float()).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.9006e-01, -4.4152e-01,  1.0690e+00,  8.5133e-01,  4.7515e-01,\n",
      "         1.4316e+00,  6.7732e-01,  1.2937e+00,  1.3502e+00,  4.2589e-01,\n",
      "        -2.1948e-02,  1.8287e-02,  5.3393e-01,  6.2777e-01,  4.0235e-01,\n",
      "         3.8769e-01,  3.0730e-01,  7.2035e-02,  5.7832e-01,  5.7177e-03,\n",
      "         1.4967e-01,  1.1717e+00, -3.1195e-01,  1.0661e+00,  1.1295e+00,\n",
      "         1.1733e-01,  6.9069e-01,  8.8820e-01,  5.2121e-02,  4.0993e-01,\n",
      "         4.1394e-01, -5.7875e-02,  7.2773e-01,  8.5857e-01,  1.4262e+00,\n",
      "         9.1457e-01,  8.6527e-01,  2.7526e-01,  9.3126e-01,  5.0425e-01,\n",
      "         1.1983e-01,  4.9441e-01,  4.8497e-01,  1.0178e+00,  2.4681e-01,\n",
      "         6.2170e-01,  4.5660e-01,  1.0780e+00,  1.7463e-01,  7.5374e-02,\n",
      "        -4.0800e-02,  4.5961e-01,  5.2406e-01,  3.2302e-01,  7.8556e-01,\n",
      "         2.9601e-01,  7.1838e-01, -3.1687e-01,  9.8314e-02,  2.9557e-01,\n",
      "         1.4868e+00,  8.4138e-01,  5.2131e-01, -2.9590e-01,  4.3673e-01,\n",
      "        -2.6020e-01,  8.6630e-01,  3.8989e-01,  9.0892e-01,  3.4975e-01,\n",
      "        -2.8248e-02,  7.2787e-01,  2.7296e-01,  3.5697e-01, -8.7367e-03,\n",
      "        -3.6271e-01,  3.4976e-01, -1.5460e-01,  4.0667e-01,  4.2496e-01,\n",
      "         1.3886e+00,  5.3881e-01,  1.5637e+00,  1.6742e+00,  4.0926e-01,\n",
      "         1.0377e+00,  1.7429e+00,  4.2418e-01, -2.0511e-01,  5.5767e-01,\n",
      "         1.6021e-02,  5.4330e-01,  5.9891e-01,  5.2006e-01, -6.1496e-02,\n",
      "         5.8455e-01,  7.0019e-01,  8.1168e-01,  6.6127e-01,  5.1150e-01,\n",
      "         3.3848e-01, -4.2292e-03, -6.0097e-01, -1.8454e-01, -8.6555e-01,\n",
      "        -4.4988e-01,  3.5165e-01,  3.7479e-01, -2.9845e-02,  2.4758e-01,\n",
      "         6.1417e-01,  5.5816e-01, -5.3879e-01, -1.2842e-01,  3.3657e-01,\n",
      "        -3.3793e-01,  8.1282e-02, -1.8758e-01, -2.9262e-02,  3.9707e-01,\n",
      "         1.2970e-01,  8.0435e-01,  3.2836e-01, -1.5178e-01, -8.3449e-02,\n",
      "         9.9938e-02,  3.7316e-01,  9.1252e-01,  1.2812e+00,  5.5391e-01,\n",
      "         2.8420e-01,  8.7623e-02,  6.3427e-01,  6.0145e-01,  1.2327e+00,\n",
      "         3.7698e-01,  7.1310e-01,  6.9104e-01,  1.2102e+00,  1.8326e-01,\n",
      "         3.2524e-02,  1.6967e-01, -3.0511e-01,  8.3116e-01,  4.8960e-01,\n",
      "         3.7110e-01,  1.4425e+00,  4.9301e-01, -2.3156e-01,  7.4532e-01,\n",
      "        -2.4727e-01, -8.9922e-01,  3.3767e-01, -7.6847e-01, -4.6381e-01,\n",
      "        -1.4593e-01, -8.8453e-01,  2.8676e-01, -2.8378e-01, -4.6313e-02,\n",
      "         2.2586e-02, -7.4660e-01, -8.7902e-01, -2.8054e-01, -4.2045e-01,\n",
      "         1.3766e-01, -2.1796e-01, -7.6101e-02, -2.3278e-01, -1.3907e-01,\n",
      "        -2.6364e-01, -8.0277e-01, -4.1799e-01, -2.0949e-01, -9.5170e-01,\n",
      "         4.4211e-01, -1.4502e-01, -2.6586e-01, -8.2804e-01, -4.8936e-01,\n",
      "        -7.4490e-01,  3.4165e-02, -3.8833e-01, -1.5714e-01,  5.3647e-01,\n",
      "        -2.5090e-01, -4.4967e-01, -1.8955e-01,  2.6730e-01, -2.3989e-01,\n",
      "         6.9237e-02, -1.5947e-02, -7.0697e-01, -2.3482e-01,  2.0649e-01,\n",
      "        -1.0808e+00, -1.1109e-01, -2.5384e-01, -3.5472e-01, -3.5671e-01,\n",
      "        -9.7890e-02, -5.5061e-01, -3.2176e-01, -6.7085e-01, -1.1182e+00,\n",
      "        -4.3040e-01, -2.9393e-01, -4.4871e-01, -7.4932e-01, -2.2016e-01,\n",
      "        -7.1073e-01, -2.5789e-01,  2.3539e-01,  2.7503e-01,  1.7403e-01,\n",
      "        -3.3313e-01,  6.5677e-01, -9.1400e-02, -6.4435e-02, -9.6631e-01,\n",
      "         6.8522e-01,  3.7171e-02, -1.7016e-01, -7.1276e-01,  3.0062e-01,\n",
      "        -4.6825e-01, -1.2797e-01, -2.4944e-01, -4.1002e-01, -3.2317e-01,\n",
      "        -5.3426e-01, -4.7125e-02, -4.4146e-01, -5.6465e-01, -3.8332e-01,\n",
      "        -1.1112e+00, -9.5862e-02, -8.1045e-01, -9.6438e-01, -8.6924e-01,\n",
      "        -1.1301e-01, -4.8610e-01, -1.1401e+00, -7.5867e-01, -7.4753e-01,\n",
      "        -6.7642e-01, -3.4350e-01, -1.1861e-01, -1.4066e-01, -7.7957e-01,\n",
      "        -7.0284e-01, -5.6686e-02, -2.8573e-01, -1.5610e-01, -9.7806e-01,\n",
      "        -5.0802e-01, -6.5954e-01, -3.0195e-01, -3.5452e-01, -8.1912e-01,\n",
      "        -1.0102e+00, -8.3624e-01, -2.2905e-01, -5.4908e-01, -5.9426e-01,\n",
      "        -5.2276e-01, -4.4392e-01, -5.9685e-02, -9.0170e-01, -3.5128e-01,\n",
      "         2.6785e-01,  8.9118e-02, -7.1298e-03, -6.1583e-01,  1.7787e-01,\n",
      "         2.1447e-01,  3.9848e-01,  7.4440e-01,  7.0292e-01,  5.3042e-01,\n",
      "         9.1851e-01, -7.4973e-01, -1.6068e-01,  1.9290e-01, -6.0419e-01,\n",
      "        -1.1744e-01, -1.0811e-01,  1.8943e-01,  2.3239e-01,  1.4389e-01,\n",
      "         1.3575e-01,  4.5905e-01, -2.6223e-01, -2.3963e-01,  6.1531e-01,\n",
      "         3.2078e-02,  6.0324e-01,  5.6908e-01,  1.4815e+00,  9.7518e-01,\n",
      "         3.2499e-01, -6.5452e-02,  6.6679e-01,  1.0860e-01,  2.9929e-02,\n",
      "         4.1098e-01, -4.8655e-01, -7.5454e-01, -8.2113e-02,  2.7506e-01,\n",
      "        -2.6788e-01, -1.6782e-01, -3.5760e-01,  1.1105e-01,  5.7872e-01,\n",
      "        -1.6381e-01, -2.2353e-02,  5.0942e-01,  7.2836e-01,  9.1052e-01,\n",
      "         1.0608e+00,  6.7677e-01,  5.6033e-01,  4.7875e-01,  4.2486e-01,\n",
      "         6.0550e-01,  1.2970e-01,  7.7363e-02,  4.8452e-02,  1.7037e-01,\n",
      "         4.1718e-01,  9.5247e-01,  6.8152e-01,  2.2480e-01,  3.4433e-01,\n",
      "         6.4550e-01,  6.3301e-01,  2.1326e-02,  2.2205e-01, -1.9606e-01,\n",
      "         2.2883e-01,  5.9599e-01,  4.9238e-01,  6.1418e-02,  4.5596e-02,\n",
      "         6.2981e-01, -1.8689e-01, -3.3404e-02,  1.2938e-01,  4.2967e-01,\n",
      "         6.5976e-01,  6.7198e-01,  4.8715e-01,  6.6706e-01, -2.1024e-01,\n",
      "         5.2176e-01,  1.5666e+00,  1.4264e+00,  1.3276e+00,  9.3065e-01,\n",
      "         7.4780e-01,  5.0302e-01,  8.3869e-01,  4.6252e-01,  6.0331e-01,\n",
      "        -4.3424e-01,  3.3804e-01, -9.1551e-02,  9.5697e-04, -1.1556e-01,\n",
      "         9.6502e-01,  1.0015e+00,  7.5716e-01, -5.6124e-01, -1.7732e-02,\n",
      "         3.8734e-01,  7.1036e-02,  7.1527e-01,  4.3814e-01,  1.9849e-01,\n",
      "         1.6767e+00,  8.0482e-01,  3.5984e-01,  2.4527e-01,  1.2280e-02,\n",
      "        -6.7375e-01, -6.0129e-01,  2.8772e-01, -4.7205e-01,  8.5371e-01,\n",
      "        -1.0510e+00,  2.2924e-01,  4.7971e-01, -3.4659e-01,  7.9653e-01,\n",
      "         9.2289e-01,  2.6653e-01,  4.7438e-01,  2.8137e-01, -4.5832e-01,\n",
      "        -3.9109e-01, -1.0843e-01,  4.8959e-01,  2.5326e-01,  2.2360e-01,\n",
      "        -1.5306e-01, -9.4336e-01,  1.4466e-01, -9.7839e-02,  1.0856e+00,\n",
      "        -7.8785e-02, -6.9883e-01,  1.0801e-01, -4.2980e-01,  1.4559e-01,\n",
      "        -4.1568e-01, -1.8292e-01,  6.0722e-01, -5.1895e-01,  8.1169e-02,\n",
      "         6.8054e-01,  1.0313e-01, -2.9365e-01, -8.6038e-02, -9.2515e-02,\n",
      "        -7.3519e-02,  1.2243e+00,  2.6169e-01, -1.9785e-01,  9.2410e-01,\n",
      "         4.3144e-01, -1.4784e-01, -7.4512e-02,  1.9510e-01, -4.3457e-01,\n",
      "        -3.7168e-01,  4.3645e-02, -4.2856e-02, -4.9467e-02,  5.4636e-01,\n",
      "         4.2405e-02, -1.6125e-02,  4.8540e-01, -6.1863e-02, -2.8044e-01,\n",
      "        -4.6313e-01, -6.4515e-01, -5.2830e-01, -5.9209e-01, -5.6111e-01,\n",
      "         6.5110e-01,  4.0282e-01, -5.7228e-01, -7.3573e-01, -1.1195e+00,\n",
      "         5.3919e-01,  3.5429e-01, -7.9806e-02, -6.5355e-01,  9.1799e-02,\n",
      "        -3.2044e-01,  3.7976e-01, -3.0776e-01,  2.4895e-01,  1.0790e+00,\n",
      "         5.4836e-01, -2.7034e-01, -3.1488e-01, -7.9882e-01, -1.3152e+00,\n",
      "        -5.3945e-01, -4.5556e-01, -1.8871e-01, -8.2019e-01, -4.7875e-01,\n",
      "        -2.9585e-01,  4.8333e-01, -3.8106e-02, -9.6433e-01,  1.0548e-01,\n",
      "        -2.7646e-02,  6.4835e-01,  1.0219e-01, -3.7273e-01,  2.2994e-01,\n",
      "         2.1465e-01,  6.5202e-01, -2.0917e-01,  1.1036e+00, -1.1765e-01,\n",
      "         3.7134e-01, -5.5735e-01, -8.3370e-01, -1.9192e-01,  4.4559e-01,\n",
      "        -5.9554e-01, -2.6822e-01, -1.7543e-01,  3.8390e-02, -5.4983e-01,\n",
      "         9.2252e-02, -7.9436e-01, -2.9619e-01, -3.5526e-01, -4.0452e-02,\n",
      "         2.3259e-01,  2.3836e-01, -1.9541e-01,  4.2582e-01, -1.3100e-01,\n",
      "         3.8483e-01, -7.6399e-01, -9.8352e-01, -2.7336e-01, -4.1180e-01,\n",
      "        -1.9749e-01, -5.6832e-01,  2.6498e-01,  3.1050e-01,  7.8939e-02,\n",
      "        -2.3246e-01, -9.1441e-01,  9.0000e-01, -1.0770e-01,  1.3827e-01,\n",
      "        -3.5304e-01, -1.0673e-01,  1.2704e-01,  3.2683e-01, -6.9084e-01,\n",
      "         8.0355e-01,  5.0804e-01, -6.3075e-01,  3.6196e-01, -1.2306e-01,\n",
      "         1.0694e-01,  3.8078e-01,  9.9993e-02,  5.3174e-01,  2.7986e-01,\n",
      "        -2.9843e-02, -1.1371e-01,  3.9859e-02, -1.6170e-01, -1.2259e+00,\n",
      "        -1.6633e-02, -2.5087e-01, -7.8104e-02,  2.0518e-01, -3.1792e-01,\n",
      "        -3.2948e-01, -3.4098e-01, -6.5896e-02,  1.7969e-01, -5.3803e-01,\n",
      "        -6.1966e-01, -3.2685e-02, -3.8294e-01,  5.2765e-01,  4.6534e-02,\n",
      "         5.0007e-01,  9.3545e-02, -7.2668e-01, -4.8001e-01, -5.8956e-01,\n",
      "         3.5774e-01, -8.0450e-01, -9.1543e-01, -6.7784e-01, -4.8206e-01,\n",
      "        -2.9922e-01, -5.8634e-01,  8.9438e-02,  3.2149e-01,  7.4970e-01,\n",
      "        -4.2862e-01,  3.6758e-01, -3.8577e-01, -4.8010e-01, -8.6179e-01,\n",
      "         6.5745e-02, -5.1943e-01,  3.2644e-01,  3.4095e-01,  2.1394e-01,\n",
      "        -1.9000e-01, -4.0425e-01, -3.9842e-02, -8.5933e-01, -7.5438e-01,\n",
      "        -1.3140e-01, -8.1486e-01, -6.9522e-01, -5.4241e-01, -1.1368e-01,\n",
      "         4.5586e-01, -3.9155e-01,  8.9690e-02, -4.1146e-01,  5.7538e-01,\n",
      "         6.8459e-01, -1.5360e-01, -1.0039e-02,  2.6630e-01,  5.3178e-01,\n",
      "        -1.0098e-01, -3.9454e-01, -7.6259e-02, -4.5342e-01, -2.1171e-01,\n",
      "        -8.1541e-01,  3.3231e-01,  2.8864e-02,  4.1386e-01,  2.4129e-01,\n",
      "         1.1683e+00,  6.2908e-01, -6.6135e-01, -6.7399e-01, -4.0867e-01,\n",
      "        -3.7968e-02, -4.7581e-01,  5.8498e-01, -9.5180e-01, -5.8706e-01,\n",
      "        -1.4626e-01,  2.0935e-01, -1.8581e-01,  1.6092e-01, -4.9047e-01,\n",
      "        -1.0227e+00, -3.9939e-01, -1.2448e+00, -3.2606e-01, -2.9241e-01,\n",
      "         4.0904e-01,  2.3763e-01, -4.6714e-01,  1.7172e-01, -7.2476e-01,\n",
      "         7.2462e-01,  2.3717e-01, -2.8714e-01,  7.6770e-01, -7.0767e-03,\n",
      "         1.9167e-01,  1.4083e-01, -1.7810e-01, -3.6391e-01,  3.4074e-01,\n",
      "        -3.3144e-01, -5.3289e-01, -3.0762e-01, -3.1885e-01, -1.2208e+00,\n",
      "        -1.0995e+00, -9.0915e-01, -6.8567e-01,  2.5914e-01, -7.3338e-01,\n",
      "         4.3024e-01, -8.5031e-01,  2.9273e-01, -4.3882e-01, -4.4469e-02,\n",
      "        -6.9961e-01, -6.4193e-02, -7.0398e-01,  5.7960e-02, -2.0918e-01,\n",
      "        -2.0012e-01,  7.0405e-03, -6.1174e-01,  3.1626e-01,  9.2218e-01,\n",
      "        -1.8243e-01,  2.4718e-01,  6.4103e-01,  9.4422e-01, -1.5750e-01,\n",
      "         2.9729e-01, -5.1785e-01, -4.2424e-03,  4.8428e-01, -6.0771e-02,\n",
      "         1.1293e+00,  1.1891e-01,  4.1631e-02, -2.4831e-01, -5.3661e-01,\n",
      "         2.6181e-01,  2.9716e-01,  2.6218e-01, -1.0603e-01,  1.4114e-01,\n",
      "        -3.2312e-01, -5.5729e-01,  2.3547e-01,  1.6713e-01,  4.7367e-02,\n",
      "        -5.5076e-01,  8.5284e-01, -1.0181e-01, -2.0538e-01, -2.4555e-01,\n",
      "         8.2134e-01, -8.6755e-01,  2.7286e-02, -4.4187e-01, -3.8785e-02,\n",
      "        -5.0579e-01, -1.1031e+00,  2.5061e-01, -3.1038e-02,  1.1086e+00,\n",
      "         3.3124e-01, -6.0941e-01, -8.9548e-01,  2.1434e-01,  5.3688e-03,\n",
      "        -1.7921e-01, -6.4796e-01,  6.8074e-01,  9.7088e-01, -4.1550e-01,\n",
      "         6.9095e-02, -1.2669e-01, -1.4970e-01,  5.8426e-04,  2.1021e-01,\n",
      "        -7.7738e-02,  2.6662e-01, -1.6539e-01,  7.9108e-01,  1.6196e-01,\n",
      "        -6.5884e-02, -7.5711e-02, -7.7196e-01, -5.4624e-02, -1.5122e+00,\n",
      "        -2.7658e-01, -8.0171e-01, -3.5934e-01, -8.1233e-02, -1.8494e-01,\n",
      "        -1.1469e+00,  8.4736e-01, -9.0092e-02,  3.1603e-02,  4.6041e-01,\n",
      "        -1.0109e+00,  3.9672e-02,  7.9934e-01, -7.1626e-01,  3.8910e-01,\n",
      "         4.2321e-01, -4.1682e-01, -2.5857e-01, -9.6427e-02,  1.8137e-02,\n",
      "        -1.2119e+00, -8.9199e-01, -8.3362e-01, -1.8739e-01, -7.9333e-01,\n",
      "        -7.3028e-01, -2.3050e-01,  5.7775e-01,  3.0574e-01,  1.1964e+00,\n",
      "        -2.5237e-02, -7.1485e-01,  1.4907e-01, -6.0832e-01, -2.4601e-01,\n",
      "        -6.3292e-01, -1.2756e-01, -2.0221e-01, -6.6342e-01, -3.8806e-01,\n",
      "        -7.6341e-02,  7.6254e-01,  6.8854e-01,  9.0490e-01, -3.3344e-01,\n",
      "        -6.1917e-01, -1.2944e-01,  7.5298e-03, -3.1824e-01,  3.6401e-01,\n",
      "        -7.4528e-01, -4.3407e-01, -8.7013e-01,  8.2502e-01, -6.7501e-01,\n",
      "        -6.2392e-01,  4.5225e-03, -6.2716e-01,  9.1860e-01,  3.3473e-01,\n",
      "         2.2756e-01, -1.4161e-01, -4.8308e-01, -4.9400e-01, -1.3904e-01,\n",
      "         5.2262e-01, -6.2047e-02,  4.5611e-02,  7.5659e-02, -7.4595e-01,\n",
      "         1.3035e+00, -7.5399e-01,  1.9588e-01, -4.7686e-01, -5.4722e-01,\n",
      "        -3.0659e-01, -4.0915e-01, -3.1164e-01, -5.8960e-01, -4.3287e-01,\n",
      "        -1.7568e-01,  2.3586e-01,  6.5345e-01, -3.4270e-01, -1.0826e+00,\n",
      "        -5.1963e-01,  1.2301e+00, -6.5531e-01, -1.8719e-01, -6.6242e-01,\n",
      "         1.9552e-02, -9.3524e-01, -8.9159e-02,  8.8725e-02, -6.7072e-01,\n",
      "         2.2470e-01, -1.2183e+00, -4.7442e-01, -1.4336e+00, -5.7047e-01,\n",
      "        -8.1253e-02, -3.1530e-01, -5.4892e-01, -3.7068e-02,  7.6798e-02,\n",
      "        -4.2875e-01, -2.2915e-01,  1.6278e-01,  6.8609e-01, -2.1586e-01,\n",
      "        -1.7329e+00,  1.9508e-01,  9.0273e-01,  2.4986e-01, -1.1510e+00,\n",
      "         3.3117e-01,  4.0132e-01, -3.2921e-01,  3.1862e-01,  6.6657e-02,\n",
      "        -7.4699e-02, -1.2102e-01, -4.9814e-01,  6.0057e-01, -1.0304e+00,\n",
      "        -6.7029e-01,  2.9358e-01, -1.5397e-01, -4.7470e-01, -1.0401e+00,\n",
      "        -2.2276e-01, -2.0235e-01, -4.3432e-02, -1.7475e-01,  2.9698e-01,\n",
      "        -3.3394e-01, -6.2594e-02,  4.3515e-02,  3.9609e-01, -1.7743e-01,\n",
      "        -3.5637e-02, -4.4612e-01, -6.6403e-01, -4.9458e-01,  1.1151e-01,\n",
      "        -1.6449e+00, -2.0385e-01, -3.6529e-01,  2.3514e-01,  9.2044e-02,\n",
      "         4.9115e-01, -3.1712e-01,  1.0172e+00, -1.1309e-01, -9.3689e-01,\n",
      "         6.5912e-02, -5.0505e-01, -6.9275e-01, -5.1713e-01, -5.4040e-01,\n",
      "         1.9027e-02,  3.0596e-01,  8.6705e-02, -8.7342e-01,  6.4824e-01,\n",
      "         1.3304e-01, -1.9116e-01, -3.1483e-01, -2.1642e-01, -1.1408e+00,\n",
      "        -1.3010e-01,  1.5594e-01,  1.0394e+00,  4.8087e-01, -4.7832e-01,\n",
      "        -3.7086e-01,  6.9584e-01, -7.7515e-01,  3.5141e-01,  2.4902e-01,\n",
      "        -6.5666e-01, -1.1391e+00, -6.2508e-01,  2.5133e-01,  1.8124e-01,\n",
      "        -4.3562e-01, -9.2221e-01,  2.4111e-01, -8.6781e-02,  2.2504e-01,\n",
      "        -5.9971e-01, -3.7258e-01,  3.9819e-01,  9.4447e-02, -5.1777e-01,\n",
      "         2.7408e-01, -6.9928e-02,  1.8522e-02, -2.7248e-01, -3.5756e-01,\n",
      "         2.6874e-01, -2.8751e-01, -1.1791e+00, -1.0137e-01,  5.8522e-01,\n",
      "        -1.3387e-01,  5.5192e-01,  1.2090e-01, -4.8306e-01,  2.8695e-01,\n",
      "         3.1226e-01,  4.0994e-02,  9.9969e-01,  8.8203e-02, -6.5463e-02,\n",
      "         8.6407e-02,  1.8305e-01,  1.9750e-01,  5.1459e-01,  4.9369e-04,\n",
      "        -6.8712e-02, -3.9732e-01, -4.2121e-02, -5.0291e-02, -5.7289e-01,\n",
      "        -3.3844e-01, -2.0321e-01,  2.8725e-01,  5.4256e-02, -2.3246e-02,\n",
      "         5.7341e-02,  4.5290e-01, -7.2808e-02, -7.9143e-02,  3.6966e-01,\n",
      "        -5.8449e-02, -8.8013e-01,  5.9286e-01, -1.2901e-01, -4.3557e-01,\n",
      "        -2.6178e-01,  5.2836e-01,  5.5729e-03,  2.9477e-01,  5.8899e-01,\n",
      "         2.9884e-01,  2.6648e-01,  5.2306e-02, -1.3141e-01, -3.4227e-01,\n",
      "         1.2135e-01,  9.4543e-01,  1.5368e-01, -7.2386e-02,  7.4703e-01,\n",
      "         1.2070e+00,  7.6452e-01, -4.9940e-01,  3.9313e-01,  3.0450e-01])\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START BUILDING CLASSIFICATION MODEL ON TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model_ft = ViT(model_name, pretrained=True)\n",
    "set_parameter_requires_grad(model_ft, feature_extracting=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = torch.nn.Linear(num_ftrs, train_dataset.num_labels)\n",
    "input_size = 384\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model_ft.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)\n",
    "\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import copy\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 2.6374 Acc: 0.3255\n",
      "val Loss: 3.3406 Acc: 0.2917\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 2.4361 Acc: 0.3681\n",
      "val Loss: 3.1599 Acc: 0.2847\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_dataset = TransformerDataset(train)\n",
    "val_dataset = TransformerDataset(val)\n",
    "test_dataset = TransformerDataset(test)\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(train_dataset), \n",
    "                    'val': torch.utils.data.DataLoader(val_dataset), \n",
    "                    'test': torch.utils.data.DataLoader(test_dataset)}\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=15, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, \"visual_transformer_mel_cropped_stacked_freeze_layers.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
